# ğŸ§  AskMyDoc â€” AI-Powered Document Q&A with FastAPI & Ollama

Welcome to **AskMyDoc**, a smart and simple FastAPI app that lets you ask questions about your documents â€” and get answers powered by **LLaMA**, running locally via [Ollama](https://ollama.com). Whether it's a PDF, DOCX, or Markdown file, this app extracts the content and lets AI do the thinking for you.

---

## ğŸš€ Features

- ğŸ“„ Supports `.pdf`, `.docx`, and `.md` files
- ğŸ¤– Uses **LLaMA** via **Ollama** for local AI inference
- âš¡ FastAPI backend for quick and scalable performance
- ğŸ§ª Clean architecture with modular text extraction
- ğŸ” No cloud dependency â€” your data stays local!

---

## ğŸ§° Requirements

Before you begin, make sure you have:

- Python 3.8+
- [Ollama installed locally](https://ollama.com/download)
- A LLaMA model pulled (e.g. `ollama pull llama3`)
- Git (optional, for cloning)

---

## ğŸ Setting Up Your Python Environment

Letâ€™s get your virtual environment ready:

```bash
# Clone the repository
git clone https://github.com/your-username/askmydoc.git
cd askmydoc

# Create a virtual environment
python -m venv venv

# Activate it
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## Request example

```bash
POST

Body:form-data

key           |       value
------------------------------
files          |       UploadFile
questions  |       FaÃ§a 15 perguntas em relaÃ§Ã£o a esse documento

```



